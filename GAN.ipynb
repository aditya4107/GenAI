{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.007496Z","iopub.status.busy":"2024-04-30T17:51:53.007107Z","iopub.status.idle":"2024-04-30T17:51:53.013257Z","shell.execute_reply":"2024-04-30T17:51:53.012110Z","shell.execute_reply.started":"2024-04-30T17:51:53.007464Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.015878Z","iopub.status.busy":"2024-04-30T17:51:53.015516Z","iopub.status.idle":"2024-04-30T17:51:53.302964Z","shell.execute_reply":"2024-04-30T17:51:53.302089Z","shell.execute_reply.started":"2024-04-30T17:51:53.015853Z"},"trusted":true},"outputs":[],"source":["(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.304454Z","iopub.status.busy":"2024-04-30T17:51:53.304141Z","iopub.status.idle":"2024-04-30T17:51:53.880282Z","shell.execute_reply":"2024-04-30T17:51:53.879426Z","shell.execute_reply.started":"2024-04-30T17:51:53.304428Z"},"trusted":true},"outputs":[],"source":["train_images = train_images.reshape(\n","    train_images.shape[0], 28, 28, 1).astype('float32')\n","# Normalize the images to [-1, 1]\n","train_images = (train_images - 127.5) / 127.5\n","BUFFER_SIZE = 60000\n","BATCH_SIZE = 256\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.881728Z","iopub.status.busy":"2024-04-30T17:51:53.881430Z","iopub.status.idle":"2024-04-30T17:51:53.896408Z","shell.execute_reply":"2024-04-30T17:51:53.895360Z","shell.execute_reply.started":"2024-04-30T17:51:53.881693Z"},"trusted":true},"outputs":[],"source":["def make_generator_model(dim):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(dim,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Reshape((7, 7, 256)))\n","    # Note: None is the batch size\n","    model.add(layers.Conv2DTranspose(\n","        256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(\n","        128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(\n","        64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2),\n","              padding='same', use_bias=False, activation='tanh'))\n","\n","    return model\n","\n","\n","def make_discriminator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n","                            input_shape=[28, 28, 1]))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.899452Z","iopub.status.busy":"2024-04-30T17:51:53.899115Z","iopub.status.idle":"2024-04-30T17:51:53.913412Z","shell.execute_reply":"2024-04-30T17:51:53.912380Z","shell.execute_reply.started":"2024-04-30T17:51:53.899421Z"},"trusted":true},"outputs":[],"source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","# noise = tf.random.normal([1, 64])\n","# generator = make_generator_model(64)\n","# discriminator = make_discriminator_model()\n","# generated_image = generator(noise, training=False)\n","# print(generated_image.shape)\n","# decision = discriminator(generated_image)\n","\n","\n","# print(decision)\n","# plt.imshow(generated_image[0, :, :, 0], cmap='gray')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.914704Z","iopub.status.busy":"2024-04-30T17:51:53.914456Z","iopub.status.idle":"2024-04-30T17:51:53.931310Z","shell.execute_reply":"2024-04-30T17:51:53.930448Z","shell.execute_reply.started":"2024-04-30T17:51:53.914685Z"},"trusted":true},"outputs":[],"source":["def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","\n","def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.932745Z","iopub.status.busy":"2024-04-30T17:51:53.932437Z","iopub.status.idle":"2024-04-30T17:51:53.944378Z","shell.execute_reply":"2024-04-30T17:51:53.943535Z","shell.execute_reply.started":"2024-04-30T17:51:53.932712Z"},"trusted":true},"outputs":[],"source":["class Trainer():\n","\tdef __init__(self, gen,dis, g_opt,d_opt,dim):\n","\t\tself.gen = gen\n","\t\tself.dis =dis\n","\t\tself.g_opt = g_opt\n","\t\tself.d_opt = d_opt\n","\t\tself.dim =dim\n","   \n","\n","\t@tf.function\n","\tdef train_step(self,images):\n","\t\tnoise = tf.random.normal([BATCH_SIZE, self.dim])\n","\n","\t\twith tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","\t\t\tgenerated_images = self.gen(noise, training=True)\n","\n","\t\t\treal_output = self.dis(images, training=True)\n","\t\t\tfake_output = self.dis(generated_images, training=True)\n","\n","\t\t\tgen_loss = generator_loss(fake_output)\n","\t\t\tdisc_loss = discriminator_loss(real_output, fake_output)\n","\n","\t\tgradients_of_generator = gen_tape.gradient(\n","\t\t\tgen_loss, self.gen.trainable_variables)\n","\t\tgradients_of_discriminator = disc_tape.gradient(\n","\t\t\tdisc_loss, self.dis.trainable_variables)\n","\n","\t\tself.g_opt.apply_gradients(\n","\t\t\tzip(gradients_of_generator, self.gen.trainable_variables))\n","\t\tself.d_opt.apply_gradients(\n","\t\t\tzip(gradients_of_discriminator, self.dis.trainable_variables))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.947418Z","iopub.status.busy":"2024-04-30T17:51:53.947112Z","iopub.status.idle":"2024-04-30T17:51:53.956562Z","shell.execute_reply":"2024-04-30T17:51:53.955768Z","shell.execute_reply.started":"2024-04-30T17:51:53.947396Z"},"trusted":true},"outputs":[],"source":["def generate_and_save_images(model, epoch, test_input,dim):\n","\tpredictions = model(test_input, training=False)\n","\tfig = plt.figure(figsize=(10, 10))\n","\tfor i in range(predictions.shape[0]):\n","\t\tplt.subplot(1, 5, i+1)\n","\t\tplt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n","\t\tplt.axis('off')\n","\tplt.savefig('image_at_epoch_{:04d}_{:02d}.png'.format(epoch,dim))\n","\tplt.show()\n","\n","def train(dataset, epochs,dim,gen,dis,d_opt,g_opt):\n","\tt = Trainer(gen,dis,g_opt,d_opt,dim)\n","\tseed = tf.random.normal([5, dim])\n","\n","\tfor epoch in range(epochs):\n","\t\tstart = time.time()\n","\t\tfor image_batch in dataset:\n","\t\t\tt.train_step(image_batch)\n","\t\t# Produce images for the GIF as you go\n","\t\tdisplay.clear_output(wait=True)\n","\t\tgenerate_and_save_images(gen,\n","\t\t\t\t\t\t\t\tepoch + 1,\n","\t\t\t\t\t\t\t\tseed,dim)\n","\n","\t\tprint('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n","\n","\tdisplay.clear_output(wait=True)\n","\tgenerate_and_save_images(gen,\n","\t\t\t\t\t\t\tepochs,\n","\t\t\t\t\t\t\tseed,dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T17:51:53.957750Z","iopub.status.busy":"2024-04-30T17:51:53.957472Z","iopub.status.idle":"2024-04-30T18:16:15.381798Z","shell.execute_reply":"2024-04-30T18:16:15.379909Z","shell.execute_reply.started":"2024-04-30T17:51:53.957706Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 40\n","num_examples = 5\n","\n","for dim in [16,32,64]:\n","\tgenerator = make_generator_model(dim)\n","\tdiscriminator = make_discriminator_model()\n","\tgenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","\tdiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","\tseed = tf.random.normal([num_examples, dim])\n","\ttrain(train_dataset, EPOCHS,dim,generator,discriminator,discriminator_optimizer,generator_optimizer)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T18:16:15.386024Z","iopub.status.busy":"2024-04-30T18:16:15.385409Z","iopub.status.idle":"2024-04-30T18:16:15.395388Z","shell.execute_reply":"2024-04-30T18:16:15.394257Z","shell.execute_reply.started":"2024-04-30T18:16:15.385970Z"},"trusted":true},"outputs":[],"source":["def make_gif(latent_dim):\n","\tanim_file = 'GAN{:d}.gif'.format(latent_dim)\n","\twith imageio.get_writer(anim_file, mode='I') as writer:\n","\t\tfilenames = ['./image_at_epoch_{:04d}_{:02d}.png'.format(\n","\t\t\ti, latent_dim) for i in range(1, EPOCHS+1)]\n","\t\t# filenames = sorted(filenames)\n","\n","\t\tfor filename in filenames:\n","\t\t\timage = imageio.imread(filename)\n","\t\t\twriter.append_data(image)\n","\t\timage = imageio.imread(filename)\n","\t\twriter.append_data(image)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
