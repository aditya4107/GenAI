{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_again = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "import os\n",
    "from os import listdir\n",
    "import cv2\n",
    "from numpy import asarray, vstack, savez_compressed\n",
    "from numpy.random import randint\n",
    "from glob import glob\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.image as tfi\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import ReLU, Input,Conv2D,Dropout,LeakyReLU, Activation, Concatenate, Conv2DTranspose\n",
    "from keras.models import load_model,Model ,Sequential\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size=(64, 64), max_images=None):\n",
    "    data_list = []\n",
    "    for filename in listdir(path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Filter for specific image file extensions\n",
    "            pixels = load_img(path + filename, target_size=size)\n",
    "            pixels = img_to_array(pixels)\n",
    "            data_list.append(pixels)\n",
    "            if max_images and len(data_list) >= max_images:\n",
    "                break\n",
    "    return np.asarray(data_list)\n",
    "\n",
    "if load_again:\n",
    "    man_glass_path = \"D:\\Assignments\\Gen AI\\Part B\\CycleGan_Train_q2\\TrainA\\\\\"\n",
    "    man_noglass_path = \"D:\\Assignments\\Gen AI\\Part B\\CycleGan_Train_q2\\TrainB\\\\\"\n",
    "\n",
    "    dataA = load_images(man_glass_path, max_images=None)\n",
    "    print('loaded dataA', dataA.shape)\n",
    "\n",
    "    dataB = load_images(man_noglass_path, max_images=None)\n",
    "    print('loaded dataB', dataB.shape)\n",
    "    filename = 'noglass2glass.npz'#'women2men.npz'\n",
    "    np.savez_compressed(filename, dataA=dataA, dataB=dataB)\n",
    "\n",
    "    print('Saved dataset:', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "if load_again or 1:\n",
    "    data = load('noglass2glass.npz')\n",
    "    # data = load('women2men.npz')\n",
    "    dataA, dataB = data['dataA'], data['dataB']\n",
    "    print('Loaded data:', dataA.shape, dataB.shape)\n",
    "    n_samples = 4\n",
    "    # plot original image\n",
    "    for i in range (n_samples):\n",
    "        plt.subplot(2 , n_samples,1+i )\n",
    "        plt.axis('off')\n",
    "        plt.imshow(dataA[i+5].astype('uint8'))\n",
    "    # plot target image\n",
    "    for i in range (n_samples):\n",
    "        plt.subplot(2 , n_samples,1+n_samples+i )\n",
    "        plt.axis('off')\n",
    "        plt.imshow(dataB[i+5].astype('uint8'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape):\n",
    "    #weight initialization\n",
    "    init = RandomNormal(stddev = 0.02)\n",
    "    #source image input\n",
    "    input_image = Input(shape = image_shape)\n",
    "    #c64 \n",
    "    x = Conv2D(64,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(input_image)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    #c128 \n",
    "    x = Conv2D(128,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    #c256\n",
    "    x = Conv2D(256,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    #c512\n",
    "    x = Conv2D(512,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "\n",
    "    x = Conv2D(512,(4,4) , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    out_put = Conv2D(1, (4, 4), padding='same', kernel_initializer=init, use_bias=False)(x)\n",
    "\n",
    "    model = Model(input_image, out_put)\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "\n",
    "    return model\n",
    "    \n",
    "image_shape = (64, 64, 3)\n",
    "discriminator = define_discriminator(image_shape)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(filters, layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    #print(layer.shape)  # print the shape of the previous layer\n",
    "    \n",
    "    x = Conv2D(filters, (3,3), padding='same', kernel_initializer=init)(layer)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (3,3), padding='same', kernel_initializer=init)(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    # skip connection\n",
    "    x = Concatenate()([x, layer])\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, layer, size=3, strides=2, activation=None, index=None, norm=True):\n",
    "    x = Conv2D(filters, kernel_size=size, strides=strides, padding ='same', kernel_initializer='he_normal', use_bias=False)(layer)\n",
    "    x = InstanceNormalization(axis=-1)(x)    \n",
    "    x = LeakyReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the generator model\n",
    "def define_generator(image_shape, n_resnet=9):\n",
    "    #weight initialization\n",
    "    init = RandomNormal(stddev = 0.02)\n",
    "    #source image input\n",
    "    input_image = Input(shape = image_shape)\n",
    "    #c64 \n",
    "    x = Conv2D(64,(7,7) , padding = 'same', kernel_initializer = init)(input_image)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    #c128 \n",
    "    x = Conv2D(128,(3,3), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    #c256\n",
    "    x = Conv2D(256,(3,3), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    for i in range(n_resnet):\n",
    "        x = resnet_block(256 , x)\n",
    "        \n",
    "    # Add Conv2DTranspose layers to upscale the image to the desired shape\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same', kernel_initializer=init)(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same', kernel_initializer=init)(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(3, (7, 7), padding='same', kernel_initializer=init)(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    out_image = Activation('tanh')(x)\n",
    "\n",
    "    model = Model(input_image, out_image)\n",
    "    return model\n",
    "image_shape = (64, 64, 3)\n",
    "generator = define_generator(image_shape)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Reshape\n",
    "\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    g_model_1.trainable = True\n",
    "    d_model.trainable = False\n",
    "    g_model_2.trainable = False\n",
    "    \n",
    "    # Input for generated images\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    \n",
    "    # Resize generated images to the shape expected by the discriminator\n",
    "    resized_gen = Lambda(lambda x: tf.image.resize(x, (64, 64), method=tf.image.ResizeMethod.BILINEAR))(input_gen)\n",
    "    \n",
    "    # Forward pass through the generator and discriminator\n",
    "    gen_1_out = g_model_1(resized_gen)\n",
    "    output_d = d_model(gen_1_out)\n",
    "    \n",
    "    # Input for identity mapping\n",
    "    input_id = Input(shape=image_shape)\n",
    "\n",
    "    # Forward pass for identity mapping\n",
    "    output_id = g_model_1(input_id)\n",
    "    \n",
    "    # Forward and backward cycle loss\n",
    "    output_f = g_model_2(gen_1_out)\n",
    "    gen_2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen_2_out)\n",
    "    \n",
    "    # Define the composite model\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    \n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    \n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(filename):\n",
    "    data = load(filename)\n",
    "    X1,X2 = data['dataA'],data['dataB']\n",
    "    X1 = (X1-127.5)/127.5 #for source image\n",
    "    X2 = (X2-127.5)/127.5 # for corresponding target images\n",
    "    return [X1,X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # choose random instances\n",
    "    ix = randint(0,dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # Generate a batch of random noise as input for the generator\n",
    "    X = g_model.predict(dataset)\n",
    "    \n",
    "    # Create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape,patch_shape, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the generator model to file\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    filename1 = 'g_model_AtoB_%06d.h5' %(step +1)\n",
    "    g_model_AtoB.save(filename1)\n",
    "    filename2 = 'g_model_BtoA_%06d.h5' %(step +1)\n",
    "    g_model_BtoA.save(filename2)\n",
    "    print('>saved:%s and %s' %(filename1,filename2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update image pool for fake image\n",
    "import random  # Import the random module\n",
    "\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # Stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random.random() < 0.5:  # Use random.random() instead of random() here\n",
    "            # Use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # Replace an existing image and use the replaced image\n",
    "            ix = np.random.randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)  # This line should be outside the for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image , title = None):\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(g_AB, g_BA, n_images=1):\n",
    "    for i in range(n_images):\n",
    "        id = np.random.randint(len(dataA))\n",
    "        data = load('noglass2glass.npz')\n",
    "        celeb, cartoon = dataA[id], dataB[id]\n",
    "        celeb_pred, cartoon_pred = g_BA.predict(tf.expand_dims(cartoon, axis=0))[0], g_AB.predict(tf.expand_dims(celeb, axis=0))[0]\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        plt.subplot(1, 4, 1)\n",
    "        show_image(celeb.astype('uint8'), title='Original Glass')\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        show_image(cartoon_pred, title='Glass to No Glass')\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        show_image(cartoon.astype('uint8'), title='Original No Glass')\n",
    "        \n",
    "        plt.subplot(1, 4, 4)\n",
    "        show_image(celeb_pred, title='No Glass to Glass')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA,epochs=10, chunk=1):\n",
    "    #define peroperties of the training run\n",
    "    n_epochs, n_batch = epochs, 1\n",
    "    #determine the output square shape of discriminator\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    #unpack dataset\n",
    "    trainA, trainB = dataset[0], dataset[1]\n",
    "    #prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    #calcute the number of batches per training epoch\n",
    "    batch_per_epoch = int(len(trainA)/n_batch)\n",
    "    #calcute the number of training iteration\n",
    "    n_steps = batch_per_epoch \n",
    "    #manually enumerate epochs\n",
    "    for j in tqdm(range(n_epochs), desc='Epochs'):\n",
    "        for i in tqdm(range(n_steps), desc='Batchs'):\n",
    "            #select a batch of real sample\n",
    "            X_realA, y_realA = generate_real_samples(trainA,n_batch, n_patch)\n",
    "            X_realB, y_realB = generate_real_samples(trainB,n_batch, n_patch)\n",
    "            \n",
    "            #genarate a batch of fake sample\n",
    "            X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "            X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            #update fakes from pool\n",
    "            X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "            X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "            \n",
    "            #update generator B->A via adversarial and cycle loss\n",
    "            gen_loss2, _, _, _,_ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "            # update discriminator for A->[real/fake]\n",
    "            dA_loss_1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "            dA_loss_2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "            \n",
    "            #update generator A->B via adversarial and cycle loss\n",
    "            gen_loss1, _, _, _,_ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "            \n",
    "            # update discriminator for B->[real/fake]\n",
    "            dB_loss_1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "            dB_loss_2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "            \n",
    "            #summerize performance\n",
    "            print('>%d, dA[%.3f ,%.3f ] dB[%.3f ,%.3f] g[%.3f ,%.3f]' %(i+1,dA_loss_1,dA_loss_2, dB_loss_1,dB_loss_2,gen_loss1,gen_loss2))\n",
    "\n",
    "            del X_realA, X_realB, y_realA, y_realB, X_fakeA, X_fakeB, y_fakeA, y_fakeB\n",
    "\n",
    "        if(j%chunk)==0:\n",
    "            show_preds(g_model_AtoB,g_model_BtoA, n_images=1)\n",
    "                #save the models\n",
    "            g_model_AtoB.save('Generator_Glass_to_NoGlass_' + str(j) + '.h5')\n",
    "            g_model_BtoA.save('Generator_NoGlass_to_Glass_' + str(j) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image data\n",
    "dataset = load_real_samples ('noglass2glass.npz')\n",
    "\n",
    "print ('Loaded',dataset[0].shape,dataset[1].shape)\n",
    "#define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "#generator:A->B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "#generator:B->A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "#discriminator A-[real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "#discriminator B-[real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "#composite : A->B ->[real/fake ,A ]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B,g_model_BtoA,image_shape)\n",
    "#composite : B->A ->[real/fake ,B ]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A,g_model_AtoB,image_shape)\n",
    "# train(dataset,d_model_A,d_model_B, g_model_AtoB,g_model_BtoA,c_model_AtoB, c_model_BtoA , epochs=10, chunk=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "g_model_AtoB = load_model(r\"D:\\Assignments\\Gen AI\\Part B\\Generator_Glass_to_NoGlass_.h5\")\n",
    "g_model_BtoA = load_model(r\"D:\\Assignments\\Gen AI\\Part B\\Generator_NoGlass_to_Glass_.h5\")\n",
    "\n",
    "\n",
    "\n",
    "# g_model_AtoB = load_model(r\"D:\\Assignments\\Gen AI\\Part B\\Generator_woman_to_man_.h5\")\n",
    "# g_model_BtoA = load_model(r\"D:\\Assignments\\Gen AI\\Part B\\Generator_man_to_woman_.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds(g_model_AtoB, g_model_BtoA ,n_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
