{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-04-30T16:41:33.732950Z","iopub.status.busy":"2024-04-30T16:41:33.731923Z","iopub.status.idle":"2024-04-30T16:42:33.066942Z","shell.execute_reply":"2024-04-30T16:42:33.065994Z","shell.execute_reply.started":"2024-04-30T16:41:33.732919Z"},"id":"lm0MCrB0aUxm","outputId":"d3ae173c-2cfb-49fe-a72a-0d5507d8b72f","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import MNIST\n","\n","\n","def show_images(datset, num_samples=20, cols=4):\n","    plt.figure(figsize=(15, 15))\n","    for i, img in enumerate(data):\n","        if i == num_samples:\n","            break\n","        plt.subplot(int(num_samples/cols) + 1, cols, i + 1)\n","        plt.imshow(img[0])\n","\n","\n","data = MNIST(root=\"./dataset\", download=True)\n","show_images(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:42:33.069483Z","iopub.status.busy":"2024-04-30T16:42:33.069060Z","iopub.status.idle":"2024-04-30T16:42:33.152071Z","shell.execute_reply":"2024-04-30T16:42:33.151265Z","shell.execute_reply.started":"2024-04-30T16:42:33.069448Z"},"id":"X-tnaDzCaUxp","trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","\n","def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n","    return torch.linspace(start, end, timesteps)\n","\n","\n","def get_index_from_list(vals, t, x_shape):\n","    batch_size = t.shape[0]\n","    out = vals.gather(-1, t.cpu())\n","    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n","\n","\n","def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n","    noise = torch.randn_like(x_0)\n","    sqrt_alphas_cumprod_t = get_index_from_list(\n","        sqrt_alphas_cumprod, t, x_0.shape)\n","    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n","        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n","    )\n","    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n","        + sqrt_one_minus_alphas_cumprod_t.to(device) * \\\n","        noise.to(device), noise.to(device)\n","\n","\n","T = 300\n","betas = linear_beta_schedule(timesteps=T)\n","\n","# Pre-calculate different terms for closed form\n","alphas = 1. - betas\n","alphas_cumprod = torch.cumprod(alphas, axis=0)\n","alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n","sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n","sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n","sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n","posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:42:33.153702Z","iopub.status.busy":"2024-04-30T16:42:33.153334Z","iopub.status.idle":"2024-04-30T16:42:33.236761Z","shell.execute_reply":"2024-04-30T16:42:33.235908Z","shell.execute_reply.started":"2024-04-30T16:42:33.153669Z"},"id":"sRHWd4WlaUxp","trusted":true},"outputs":[],"source":["from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","IMG_SIZE = 32\n","BATCH_SIZE = 128\n","\n","\n","def load_transformed_dataset():\n","    data_transforms = [\n","        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),  # Scales data into [0,1]\n","        transforms.Lambda(lambda t: (t * 2) - 1)  # Scale between [-1, 1]\n","    ]\n","    data_transform = transforms.Compose(data_transforms)\n","\n","    train = MNIST(root=\"./dataset\", download=True,\n","                  transform=data_transform)\n","\n","    return train\n","\n","\n","def show_tensor_image(image):\n","    reverse_transforms = transforms.Compose([\n","        transforms.Lambda(lambda t: (t + 1) / 2),\n","        transforms.Lambda(lambda t: t.permute(1, 2, 0)),  # CHW to HWC\n","        transforms.Lambda(lambda t: t * 255.),\n","        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n","        transforms.ToPILImage(),\n","    ])\n","    # print(image.shape)\n","\n","    if len(image.shape) == 4:\n","        # print(image.shape)\n","        image = image[0, :, :, :]\n","    plt.imshow(reverse_transforms(image))\n","\n","\n","data = load_transformed_dataset()\n","dataloader = DataLoader(data, batch_size=BATCH_SIZE,\n","                        shuffle=True, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"execution":{"iopub.execute_input":"2024-04-30T16:42:33.239532Z","iopub.status.busy":"2024-04-30T16:42:33.239194Z","iopub.status.idle":"2024-04-30T16:42:34.407086Z"},"id":"PrZstFtzaUxq","outputId":"7d7ebb6c-15e0-466a-8e79-1bfa34dc1321","trusted":true},"outputs":[],"source":["image = next(iter(dataloader))[0]\n","\n","plt.figure(figsize=(15, 15))\n","plt.axis('off')\n","num_images = 10\n","stepsize = int(T/num_images)\n","\n","for idx in range(0, T, stepsize):\n","    t = torch.Tensor([idx]).type(torch.int64)\n","    plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n","    img, noise = forward_diffusion_sample(image, t)\n","    show_tensor_image(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-30T16:42:34.408543Z","iopub.status.busy":"2024-04-30T16:42:34.408264Z","iopub.status.idle":"2024-04-30T16:42:34.602013Z","shell.execute_reply":"2024-04-30T16:42:34.601284Z","shell.execute_reply.started":"2024-04-30T16:42:34.408518Z"},"id":"vfdGgIpCaUxq","outputId":"c0a717d3-4419-4ee0-8d0a-71d463357a0e","trusted":true},"outputs":[],"source":["from torch import nn\n","import math\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n","        super().__init__()\n","        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n","        if up:\n","            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n","            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n","        else:\n","            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n","            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n","        self.bnorm1 = nn.BatchNorm2d(out_ch)\n","        self.bnorm2 = nn.BatchNorm2d(out_ch)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, t, ):\n","        h = self.bnorm1(self.relu(self.conv1(x)))\n","        # print(\"h before\",h.shape)\n","        time_emb = self.relu(self.time_mlp(t))\n","        # print(time_emb.shape)\n","        time_emb = time_emb[(..., ) + (None, ) * 2]\n","        h = h + time_emb\n","        # print(\"h\",h.shape)\n","        h = self.bnorm2(self.relu(self.conv2(h)))\n","        # print(\"h final\",h.shape)\n","        return self.transform(h)\n","\n","\n","class SinusoidalPositionEmbeddings(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, time):\n","        device = time.device\n","        half_dim = self.dim // 2\n","        embeddings = math.log(10000) / (half_dim - 1)\n","        embeddings = torch.exp(torch.arange(\n","            half_dim, device=device) * -embeddings)\n","        embeddings = time[:, None] * embeddings[None, :]\n","        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n","\n","        return embeddings\n","\n","\n","class SimpleUnet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        image_channels = 1\n","        down_channels = (32, 64, 128, 256, 512)\n","        up_channels = (512, 256, 128, 64, 32)\n","        out_dim = 1\n","        time_emb_dim = 32\n","\n","        self.time_mlp = nn.Sequential(\n","            SinusoidalPositionEmbeddings(time_emb_dim),\n","            nn.Linear(time_emb_dim, time_emb_dim),\n","            nn.ReLU()\n","        )\n","\n","        # Initial projection\n","        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n","\n","        # Downsample\n","        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1],\n","                                    time_emb_dim)\n","                                    for i in range(len(down_channels)-1)])\n","        # Upsample\n","        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1],\n","                                        time_emb_dim, up=True)\n","                                  for i in range(len(up_channels)-1)])\n","\n","        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n","\n","    def forward(self, x, timestep):\n","        t = self.time_mlp(timestep)\n","        # print(\"x\", x.shape)\n","\n","        x = self.conv0(x)\n","        # print(\"x1\",x.shape)\n","        residual_inputs = []\n","        for down in self.downs:\n","            x = down(x, t)\n","            residual_inputs.append(x)\n","        for up in self.ups:\n","            residual_x = residual_inputs.pop()\n","            x = torch.cat((x, residual_x), dim=1)\n","            x = up(x, t)\n","        # print(\"unet\",self.output(x).shape)\n","        return self.output(x)\n","\n","\n","model = SimpleUnet()\n","print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:42:34.603302Z","iopub.status.busy":"2024-04-30T16:42:34.603010Z","iopub.status.idle":"2024-04-30T16:42:34.607867Z","shell.execute_reply":"2024-04-30T16:42:34.606965Z","shell.execute_reply.started":"2024-04-30T16:42:34.603277Z"},"id":"-T5zJmvJaUxr","trusted":true},"outputs":[],"source":["def get_loss(model, x_0, t):\n","    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n","    noise_pred = model(x_noisy, t)\n","    return F.l1_loss(noise, noise_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:42:34.609345Z","iopub.status.busy":"2024-04-30T16:42:34.609055Z","iopub.status.idle":"2024-04-30T16:42:34.620492Z","shell.execute_reply":"2024-04-30T16:42:34.619620Z","shell.execute_reply.started":"2024-04-30T16:42:34.609321Z"},"id":"clFYxNP5aUxr","trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def sample_timestep(x, t):\n","    betas_t = get_index_from_list(betas, t, x.shape)\n","    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n","        sqrt_one_minus_alphas_cumprod, t, x.shape\n","    )\n","    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n","\n","    # (current image - noise prediction)\n","    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t)\n","    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n","\n","    if t == 0:\n","        return model_mean\n","    else:\n","        noise = torch.randn_like(x)\n","        return model_mean + torch.sqrt(posterior_variance_t) * noise\n","\n","@torch.no_grad()\n","def sample_plot_image(IMG,tRand=None):\n","    img_size = IMG_SIZE\n","    img = IMG\n","    plt.figure(figsize=(15, 15))\n","    plt.axis('off')\n","    num_images = 10\n","    stepsize = int(T/num_images)\n","\n","    for i in range(0, T)[::-1]:\n","        t = torch.full((1,), i, device=device, dtype=torch.long)\n","        img = sample_timestep(img, t)\n","        img = torch.clamp(img, -1.0, 1.0)\n","        if i % stepsize == 0:\n","            plt.subplot(1, num_images, num_images-int(i/stepsize))\n","            show_tensor_image(img.detach().cpu())\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"execution":{"iopub.execute_input":"2024-04-30T16:43:06.054591Z","iopub.status.busy":"2024-04-30T16:43:06.054239Z","iopub.status.idle":"2024-04-30T16:43:06.059020Z","shell.execute_reply":"2024-04-30T16:43:06.058059Z","shell.execute_reply.started":"2024-04-30T16:43:06.054563Z"},"id":"8wUcS6sil4IG","outputId":"7e60f06b-37df-45e9-cf35-636c6e09f9ad","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-04-30T16:43:14.169030Z","iopub.status.busy":"2024-04-30T16:43:14.168418Z","iopub.status.idle":"2024-04-30T17:34:57.828560Z","shell.execute_reply":"2024-04-30T17:34:57.827537Z","shell.execute_reply.started":"2024-04-30T16:43:14.168989Z"},"id":"Yh5LU9JTaUxr","outputId":"a1ece921-6462-42e5-ea42-b4cb48d097d9","trusted":true},"outputs":[],"source":["from torch.optim import Adam\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","IMG = torch.randn((1, 1, IMG_SIZE, IMG_SIZE), device=device)\n","model.to(device)\n","optimizer = Adam(model.parameters(), lr=0.001)\n","epochs = 100  \n","\n","for epoch in range(epochs):\n","    for step, batch in enumerate(dataloader):\n","      optimizer.zero_grad()\n","\n","      t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n","      loss = get_loss(model, batch[0], t)\n","      loss.backward()\n","      optimizer.step()\n","\n","      if epoch % 1 == 0 and step == 0:\n","        print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")\n","        sample_plot_image(IMG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-SwE_2L3D56"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KY0LLgAv3DzY"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":4}
